{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a0cedaf",
   "metadata": {},
   "source": [
    "# MGMT59000 HW1\n",
    "# Shivam Mishra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60b1254b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\pc\\anaconda3\\lib\\site-packages (2.15.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.15.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.23.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.7.1)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.60.0)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.27.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9842a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "253367da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "391/391 [==============================] - 3s 4ms/step - loss: 0.4501 - accuracy: 0.8725 - val_loss: 0.2349 - val_accuracy: 0.9365\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.1968 - accuracy: 0.9431 - val_loss: 0.1764 - val_accuracy: 0.9494\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.1486 - accuracy: 0.9569 - val_loss: 0.1489 - val_accuracy: 0.9573\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.1199 - accuracy: 0.9650 - val_loss: 0.1303 - val_accuracy: 0.9626\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.1009 - accuracy: 0.9713 - val_loss: 0.1215 - val_accuracy: 0.9654\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.0875 - accuracy: 0.9740 - val_loss: 0.1147 - val_accuracy: 0.9669\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.0763 - accuracy: 0.9777 - val_loss: 0.1138 - val_accuracy: 0.9686\n",
      "Epoch 8/10\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.0670 - accuracy: 0.9802 - val_loss: 0.1115 - val_accuracy: 0.9669\n",
      "Epoch 9/10\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.0577 - accuracy: 0.9829 - val_loss: 0.1041 - val_accuracy: 0.9702\n",
      "Epoch 10/10\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.0512 - accuracy: 0.9842 - val_loss: 0.1035 - val_accuracy: 0.9699\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                50240     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 52650 (205.66 KB)\n",
      "Trainable params: 52650 (205.66 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model 1 Testing set accuracy: 96.94%\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow import keras\n",
    "\n",
    "# Load and preprocess the MNIST dataset\n",
    "(X_train_pre, y_train_pre), (X_test_pre, y_test_pre) = mnist.load_data()\n",
    "\n",
    "input_dim = 784  # 28*28\n",
    "X_train = X_train_pre.reshape(X_train_pre.shape[0], input_dim)\n",
    "X_test = X_test_pre.reshape(X_test_pre.shape[0], input_dim)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255.\n",
    "X_test /= 255.\n",
    "\n",
    "# Convert class vectors to binary class matrices (one-hot encoding)\n",
    "num_classes = 10  # 0-9\n",
    "y_train = keras.utils.to_categorical(y_train_pre, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test_pre, num_classes)\n",
    "\n",
    "# Define the validation set\n",
    "validation_split = 0.166667  # Approximately 1/6 of the data\n",
    "num_validation_samples = int(X_train.shape[0] * validation_split)\n",
    "X_val = X_train[:num_validation_samples]\n",
    "y_val = y_train[:num_validation_samples]\n",
    "X_train = X_train[num_validation_samples:]\n",
    "y_train = y_train[num_validation_samples:]\n",
    "\n",
    "# Now define the model as before\n",
    "model1 = keras.Sequential([\n",
    "    keras.layers.Dense(64, activation='relu', input_shape=(input_dim,)),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model1.compile(optimizer='adam',\n",
    "               loss='categorical_crossentropy',\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "early_stopping_1 = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "model1_history = model1.fit(X_train, y_train, batch_size=128, epochs=10, validation_data=(X_val, y_val))\n",
    "\n",
    "# Model Summary and Evaluation\n",
    "model1.summary()\n",
    "_, acc1 = model1.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Model 1 Testing set accuracy: {:.2f}%\".format(acc1*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2368f6b2",
   "metadata": {},
   "source": [
    "# Model 1 \n",
    "\n",
    "    Training Accuracy: 98.42% in the last epoch.\n",
    "    Validation Accuracy: 96.99% in the last epoch.\n",
    "    Training Loss: 0.0512 in the last epoch.\n",
    "    Validation Loss: 0.1035 in the last epoch.\n",
    "    Testing Accuracy: 96.94%.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f996028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.9229 - accuracy: 0.7788 - val_loss: 0.5111 - val_accuracy: 0.8801\n",
      "Epoch 2/20\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.4418 - accuracy: 0.8896 - val_loss: 0.3659 - val_accuracy: 0.9055\n",
      "Epoch 3/20\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.3502 - accuracy: 0.9060 - val_loss: 0.3122 - val_accuracy: 0.9163\n",
      "Epoch 4/20\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.3065 - accuracy: 0.9151 - val_loss: 0.2839 - val_accuracy: 0.9228\n",
      "Epoch 5/20\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.2786 - accuracy: 0.9224 - val_loss: 0.2626 - val_accuracy: 0.9272\n",
      "Epoch 6/20\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.2577 - accuracy: 0.9279 - val_loss: 0.2485 - val_accuracy: 0.9313\n",
      "Epoch 7/20\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.2406 - accuracy: 0.9321 - val_loss: 0.2330 - val_accuracy: 0.9343\n",
      "Epoch 8/20\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.2260 - accuracy: 0.9366 - val_loss: 0.2217 - val_accuracy: 0.9351\n",
      "Epoch 9/20\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.2131 - accuracy: 0.9397 - val_loss: 0.2110 - val_accuracy: 0.9393\n",
      "Epoch 10/20\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.2013 - accuracy: 0.9436 - val_loss: 0.2030 - val_accuracy: 0.9412\n",
      "Epoch 11/20\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.1907 - accuracy: 0.9464 - val_loss: 0.1938 - val_accuracy: 0.9433\n",
      "Epoch 12/20\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.1811 - accuracy: 0.9489 - val_loss: 0.1839 - val_accuracy: 0.9453\n",
      "Epoch 13/20\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.1720 - accuracy: 0.9512 - val_loss: 0.1787 - val_accuracy: 0.9479\n",
      "Epoch 14/20\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.1638 - accuracy: 0.9537 - val_loss: 0.1747 - val_accuracy: 0.9493\n",
      "Epoch 15/20\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.1563 - accuracy: 0.9560 - val_loss: 0.1655 - val_accuracy: 0.9523\n",
      "Epoch 16/20\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.1492 - accuracy: 0.9586 - val_loss: 0.1611 - val_accuracy: 0.9529\n",
      "Epoch 17/20\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.1427 - accuracy: 0.9604 - val_loss: 0.1556 - val_accuracy: 0.9551\n",
      "Epoch 18/20\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.1365 - accuracy: 0.9619 - val_loss: 0.1524 - val_accuracy: 0.9555\n",
      "Epoch 19/20\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.1309 - accuracy: 0.9633 - val_loss: 0.1467 - val_accuracy: 0.9589\n",
      "Epoch 20/20\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.1255 - accuracy: 0.9648 - val_loss: 0.1432 - val_accuracy: 0.9581\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 128)               100480    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 111146 (434.16 KB)\n",
      "Trainable params: 111146 (434.16 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model 2 Testing set accuracy: 95.85%\n"
     ]
    }
   ],
   "source": [
    "# Model 2: Adjusted Hyperparameters with Early Stopping\n",
    "model2 = keras.Sequential([\n",
    "    keras.layers.Dense(128, activation='tanh', input_shape=(input_dim,)),\n",
    "    keras.layers.Dense(64, activation='tanh'),\n",
    "    keras.layers.Dense(32, activation='tanh'),\n",
    "    keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model2.compile(optimizer=keras.optimizers.SGD(learning_rate=0.01),\n",
    "               loss='categorical_crossentropy',\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "early_stopping2 = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "model2_history = model2.fit(X_train, y_train, batch_size=64, epochs=20, validation_data=(X_val, y_val), callbacks=[early_stopping2])\n",
    "\n",
    "# Model Summary and Evaluation\n",
    "model2.summary()\n",
    "_, acc2 = model2.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Model 2 Testing set accuracy: {:.2f}%\".format(acc2*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a6365d",
   "metadata": {},
   "source": [
    "# Model 2\n",
    "\n",
    "    Training Accuracy: 96.48% in the last epoch.\n",
    "    Validation Accuracy: 95.81% in the last epoch.\n",
    "    Training Loss: 0.1255 in the last epoch.\n",
    "    Validation Loss: 0.1432 in the last epoch.\n",
    "    Testing Accuracy: 95.88%.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6b7fbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "196/196 [==============================] - 2s 8ms/step - loss: 0.6444 - accuracy: 0.8819 - val_loss: 0.4280 - val_accuracy: 0.9229\n",
      "Epoch 2/15\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.3488 - accuracy: 0.9366 - val_loss: 0.2808 - val_accuracy: 0.9498\n",
      "Epoch 3/15\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.2571 - accuracy: 0.9514 - val_loss: 0.3428 - val_accuracy: 0.9198\n",
      "Epoch 4/15\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.2128 - accuracy: 0.9579 - val_loss: 0.2261 - val_accuracy: 0.9538\n",
      "Epoch 5/15\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.1843 - accuracy: 0.9627 - val_loss: 0.2147 - val_accuracy: 0.9536\n",
      "Epoch 6/15\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.1666 - accuracy: 0.9671 - val_loss: 0.2141 - val_accuracy: 0.9522\n",
      "Epoch 7/15\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.1542 - accuracy: 0.9689 - val_loss: 0.1958 - val_accuracy: 0.9580\n",
      "Epoch 8/15\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.1442 - accuracy: 0.9708 - val_loss: 0.1729 - val_accuracy: 0.9642\n",
      "Epoch 9/15\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.1368 - accuracy: 0.9721 - val_loss: 0.1561 - val_accuracy: 0.9687\n",
      "Epoch 10/15\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.1299 - accuracy: 0.9747 - val_loss: 0.1484 - val_accuracy: 0.9700\n",
      "Epoch 11/15\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.1254 - accuracy: 0.9748 - val_loss: 0.1620 - val_accuracy: 0.9652\n",
      "Epoch 12/15\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.1212 - accuracy: 0.9762 - val_loss: 0.1871 - val_accuracy: 0.9582\n",
      "Epoch 13/15\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.1165 - accuracy: 0.9771 - val_loss: 0.1342 - val_accuracy: 0.9728\n",
      "Epoch 14/15\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.1133 - accuracy: 0.9779 - val_loss: 0.1593 - val_accuracy: 0.9643\n",
      "Epoch 15/15\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.1086 - accuracy: 0.9791 - val_loss: 0.1406 - val_accuracy: 0.9704\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_7 (Dense)             (None, 256)               200960    \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 235146 (918.54 KB)\n",
      "Trainable params: 235146 (918.54 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model 3 Testing set accuracy: 97.23%\n"
     ]
    }
   ],
   "source": [
    "# Model 3: Further Adjustments, Regularization, and Early Stopping\n",
    "model3 = keras.Sequential([\n",
    "    keras.layers.Dense(256, activation='elu', kernel_regularizer=keras.regularizers.l2(0.001), input_shape=(input_dim,)),\n",
    "    keras.layers.Dense(128, activation='elu'),\n",
    "    keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model3.compile(optimizer=keras.optimizers.RMSprop(learning_rate=0.001),\n",
    "               loss='categorical_crossentropy',\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "early_stopping3 = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5)\n",
    "\n",
    "model3_history = model3.fit(X_train, y_train, batch_size=256, epochs=15, validation_data=(X_val, y_val), callbacks=[early_stopping3])\n",
    "\n",
    "# Model Summary and Evaluation\n",
    "model3.summary()\n",
    "_, acc3 = model3.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Model 3 Testing set accuracy: {:.2f}%\".format(acc3*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc0d54e",
   "metadata": {},
   "source": [
    "# Model 3\n",
    "\n",
    "    Training Accuracy: 97.91% in the last epoch.\n",
    "    Validation Accuracy: 97.04% in the last epoch.\n",
    "    Training Loss: 0.1086 in the last epoch.\n",
    "    Validation Loss: 0.1406 in the last epoch.\n",
    "    Testing Accuracy: 97.23%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443f0272",
   "metadata": {},
   "source": [
    "Model Comparison\n",
    "\n",
    "    Accuracy:\n",
    "        Training: Model 1 now shows the highest training accuracy, indicating a very effective fit to the training data.\n",
    "        Validation: Model 3 maintains the highest validation accuracy, closely followed by the revised Model 1.\n",
    "        Testing: Model 3 still holds the highest testing accuracy, indicating the best generalization among the three.\n",
    "\n",
    "    Loss:\n",
    "        Training and Validation Loss: The revised Model 1 shows significant improvement in training loss and maintains \n",
    "        competitive validation loss, suggesting an efficient learning process.\n",
    "\n",
    "Conclusions\n",
    "\n",
    "    Model 1: The revision showcases Model 1's strong capability to fit the training data while maintaining good \n",
    "              generalization to unseen data. The improvements in training accuracy and competitive validation accuracy \n",
    "              make it a robust choice for similar tasks.\n",
    "    Model 2: Remains the model with room for improvement, particularly in terms of optimizing its architecture \n",
    "              and hyperparameters to enhance validation and testing accuracy.\n",
    "    Model 3: Continues to exhibit the best balance between learning from the training data and generalizing to unseen data, \n",
    "              highlighted by its highest testing accuracy.\n",
    "\n",
    "Recommendations for Future Hyperparameter Tuning\n",
    "\n",
    "    Model 1: Further experimentation with regularization techniques could help improve validation and testing accuracy \n",
    "              by reducing the gap between training and validation loss.\n",
    "    Model 2: Adjusting the network architecture, experimenting with different optimizers, and tuning learning rates could \n",
    "              help improve its performance.\n",
    "    Model 3: Although it performs well, exploring dropout, batch normalization, and different activation functions could \n",
    "              provide marginal gains in accuracy and loss metrics.\n",
    "\n",
    "In conclusion, each model demonstrates unique strengths and areas for improvement. The insights from these revisions \n",
    "underscore the importance of continuous experimentation and fine-tuning in developing high-performing neural network models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
